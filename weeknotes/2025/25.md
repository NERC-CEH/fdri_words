# 2025 Week 25 DRAFT

New FDRI site going out next week, lots keeping us on our toes.

## üì∏ FDRI field cameras

There's a new observation site being set up in Wales next week, and as part of this we're deploying Raspberry Pis with an attached camera module.

This effort has been led by [Jack Hambridge](https://github.com/jacham12) in the field engineering team, with programming support and coaching by research software engineers in WP2. The cameras aren't yet being used for Phenocam-style observations, only to provide some monitoring for conditions on the site. The devices have a custom housing designed by Will in the UKCEH Engineering Workshop.

![A Raspberry Pi plus camera in its weatherproof housing](https://raw.githubusercontent.com/NERC-CEH/fdri_words/refs/heads/main/weeknotes/assets/pi_camera_housing.jpg)

They're capturing images on a schedule and uploading them directly to AWS object storage. The aim is to re-use the same interface development work that was done for COSMOS to provide the engineering team with a feed of camera images.

This is a trial installation and the Pis are not registered as Things in AWS IoT Core yet, but that's part of the intention for managing them in the future - with plenty of ideas kicking around for what can be done with tiny Linux computers in each FDRI site. 

## üå©Ô∏è Production Data on our Test Environment
![image](https://github.com/user-attachments/assets/b3359ac2-bdbd-4079-8ea2-b2fa880986fd)

With the hefran forest site going live and the other site going live next week we are now receive production data, which is heading directly into our staging/test environment. We are in the (very slow) process of procuring a production environment to help rectify this. One potential solution is to rename our test environment to production and start treating it as such, then the newly procurred environment can become our new test environment. Althought this is how things are for now, we have good practices around our data and it's stored securely and safely in an s3 bucket, which only admins having access to delete it (our deployed code doesn't have delete permissions).


In future we are looking at other ways to backup this data:
- [Backup for S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/backup-for-s3.html)
- [AWS DataSync](https://aws.amazon.com/datasync/) to our on-prem s3 ceph object storage
- Some cronjob or something to backup to the on-prem SAN which is where vast major or other project data is

## üñêÔ∏è Image data partitioning
![image](https://github.com/user-attachments/assets/443e1c42-61e3-4a71-b4bd-a066be99d89b)

Lots of back and forth on how we partition the incoming image data, this is important to get right since it's tricky to change onces the cameras get deployed since we are going live without any remote device management. The partitioning structure if setup correctly should allow our query use cases to performantly query the image data in the bucket e.g give me images from site X between date y and date z without us having to store an alongside index. We didn't get time to test the performance before going live but think the following should allow that and we can always add an index in if needed without needing to update the raspbery pi camera code.


```
/catchment=SE/site=CARGN/compound=01/type=PCAM/direction=E/date=2025-06-18/SE_CARGN_01_PCAM_E_20250618_154719.jpg
```
