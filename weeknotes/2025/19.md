# 2025 Week 19 DRAFT

## üêò Postgres, PostGIS and geoserver setup
![image](https://github.com/user-attachments/assets/9667b98e-d3cc-41b1-b631-d751e3bf529a)


Adding new technologies to our tech stack, we have spun up our first relational database of the project. We already have a lot of relational database experience on our team and this is the natural choice for working with GIS software.
This is setup in our staging account but we still made sure to do it "properly", fully written in terraform and included a bastion instance to proxy access.

## üåÄ Merging Timeseries and Phenocam Dev teams
![image](https://github.com/user-attachments/assets/0a2490c9-5191-412e-9931-6e57685e59e2)

Due to some staffing restraints the phenocam team is mostly a single person, which isn't really a team. So moving forward we are merging the phenocam and timeseries development teams, we have already spotted a number of cross-overs in the workstreams and hope this helps FDRI development knowledge sharing and building better products overall.


## üßë‚Äçü§ù‚Äçüßë UI Community Workshop
![image](https://github.com/user-attachments/assets/5bbf02ba-49c1-4085-891a-307842792874)

This week we had the first of the FDRI User Interface community workshops, where we are starting more focused engagement on the community. With the plan to feed this into the development process and continue continuous feedback throughout our development.
If this sounds interesting to your [register for the FDRI UX Workshops on 14 May](https://www.tickettailor.com/events/ukcentreforecologyandhydrology/1640978).

## üó∫Ô∏è FDRI Annual Meeting

Today is the FDRI annual meeting, reflecting on year 1 across all work packages and planning/kicking off year 2. Unfortunately I wasn't able to attend it in Wallingford, will provide an update next week. 

## üî¢ Time series data processing

This week we had a technical deep dive mostly focused on the recent updates to time series data processing. I find these extremely useful and the engagement from the team is brilliant, we used to do these a lot at the start of the project but they dropped off a bit, but now is the time to bring them back.

Main changes to the actual time series pipeline were the ability to handle and configure the handling of missing data (For example, if we have two 1 minute data points on a given day, doing a mean aggregation would return the mean of those 2 values - even though we'd expect 1440 values for a full day.) There's a few different ways users might want this to be handled which can be configured in options:
- ``{"missing": 30}`` Aggregate only if there are no more than 30 values missing in the period.
- ``{"available": 30}`` Aggregate only if there are at least 30 input values in the period.
- ``{"percent": 30}`` Aggregate only if the data in the period is at least 30 percent complete (accepts integers or floats).

Read more about this on our documention site: [https://nerc-ceh.github.io/time-stream/user_guide/timeseries_basics.html#aggregating-data](https://nerc-ceh.github.io/time-stream/user_guide/timeseries_basics.html#aggregating-data) 

## üì±Asset Management Service Requirements Gathering

This week we have a summary meeting of all the requirements that have been gathered so far for this essential part of our systems. It's been a mamoth task to collect this information from everybody and get it all in one place. This is being run by an external company (ARUP).

## Gridded Data Update ‚ôüÔ∏è

This week in Gridded land it was the [CHESS-Met](https://catalogue.ceh.ac.uk/documents/835a50df-e74f-4bfb-b593-804fd61d5eab) dataset's turn to get the [pangeo-forge](https://pangeo-forge.readthedocs.io/en/latest/index.html) treatment and be converted to [Zarr](https://zarr.dev/) ready for upload to the steadily-growing object-store of cloud-optimized datasets ready for analysis. It's been a bit of a chess-match, with the dataset putting up some interesting fights, but like any good champion I've learnt from these challenges and put some improvements into the data converter to handle more complex datasets, namely handling multi-variable datasets. 
As ever you can see my progress [over on GitHub](https://github.com/orgs/NERC-CEH/projects/13/views/1?pane=issue&itemId=102907624&issue=NERC-CEH%7Cdri_gridded_data%7C40). 
